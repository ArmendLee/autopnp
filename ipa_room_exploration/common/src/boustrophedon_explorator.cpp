#include <ipa_room_exploration/boustrophedon_explorator.h>

#define DEBUG_VISUALIZATION

// Constructor
boustrophedonExplorer::boustrophedonExplorer()
{

}

// Function that creates a room exploration path for the given map, by using the morse cellular decomposition method proposed in
//
// "H. Choset, E. Acar, A. A. Rizzi and J. Luntz,
// "Exact cellular decompositions in terms of critical points of Morse functions," Robotics and Automation, 2000. Proceedings.
// ICRA '00. IEEE International Conference on, San Francisco, CA, 2000, pp. 2270-2277 vol.3."
//
// This method takes the given map and separates it into several cells. Each cell is obstacle free and so allows an
// easier path planning. For each cell then a boustrophedon path is planned, which goes up, down and parallel to the
// upper and lower boundaries of the cell, see the referenced paper for details. This function does the following steps:
// I.	Using the Sobel operator the direction of the gradient at each pixel is computed. Using this information, the direction is
//		found that suits best for calculating the cells, i.e. such that longer cells occur, and the map is rotated in this manner.
//		This allows to use the algorithm as it was and in the last step, the found path points simply will be transformed back to the
//		original orientation.
// II.	Sweep a slice (a morse function) trough the given map and check for connectivity of this line,
//		i.e. how many connected segments there are. If the connectivity increases, i.e. more segments appear,
//		an IN event occurs that opens new separate cells, if it decreases, i.e. segments merge, an OUT event occurs that
//		merges two cells together. If an event occurs, the algorithm checks along the current line for critical points,
//		that are points that trigger the events. From these the boundary of the cells are drawn, starting from the CP
//		and going left/right until a black pixel is hit.
// III.	After all cells have been determined by the sweeping slice, the algorithm finds these by using cv::findContours().
//		This gives a set of points for each cell, that are used to create a generalizedPolygon out of each cell.
// IV.	After all polygons have been created, plan the path trough all of them for the field of view s.t. the whole area
//		is covered. To do so, first a global path trough all cells is generated, using the traveling salesmen problem
//		formulation. This produces an optimal visiting order of the cells. Next for each cell a boustrophedon path is
//		determined, which goes back and forth trough the cell and between the horizontal paths along the boundaries of
//		the cell, what ensures that the whole area of the cell is covered. For each cell the longest edge is found and it is transformed
//		s.t. this edge lies horizontal to the x-direction. This produces longer but fewer edges, what improves the path for small but long
//		cells. The startpoint of the cell-path is determined by the endpoint of the previous cell, s.t. the distance between two
//		cell-paths is minimized. The cell-path is determined in the rotated manner, so in a last step, the cell-path is transformed to
//		the originally transformed cell and after that inserted in the global path.
// V.	The previous step produces a path for the field of view. If wanted this path gets mapped to the robot path s.t.
//		the field of view follows the wanted path. To do so simply a vector transformation is applied. If the computed robot
//		pose is not in the free space, another accessible point is generated by finding it on the radius around the field of view (fov)
//		middlepoint s.t. the distance to the last robot position is minimized. If this is not wanted one has to set the
//		corresponding Boolean to false (shows that the path planning should be done for the robot footprint).
void boustrophedonExplorer::getExplorationPath(const cv::Mat& room_map, std::vector<geometry_msgs::Pose2D>& path,
		const float map_resolution, const cv::Point starting_position, const cv::Point2d map_origin,
		const float coverage_radius, const double path_eps, const bool plan_for_footprint,
		const Eigen::Matrix<float, 2, 1> robot_to_fov_vector, const double min_cell_area)
{
	// *********************** I. Find the main directions of the map and rotate it in this manner. ***********************
	// generate matrices for gradient in x/y direction
	cv::Mat gradient_x, gradient_y;

	// compute gradient in x direction
	cv::Sobel(room_map, gradient_x, CV_64F, 1, 0, 5, 1.0, 0.0, cv::BORDER_DEFAULT);

	// compute gradient in y direction
	cv::Sobel(room_map, gradient_y, CV_64F, 0, 1, 5, 1.0, 0.0, cv::BORDER_DEFAULT);

	// compute the direction of the gradient for each pixel and save the occurring gradients
	std::vector<double> gradient_directions;
	for(size_t y=0; y<room_map.rows; ++y)
	{
		for(size_t x=0; x<room_map.cols; ++x)
		{
			// check if the gradient has a value larger than zero, to only take the edge-gradients into account
			int dx= gradient_x.at<double>(y,x);
			int dy= gradient_y.at<double>(y,x);
			if(dy*dy+dx*dx > 0.0)
			{
				double current_gradient = std::atan2(dy, dx);
				gradient_directions.push_back(0.1*(double)((int)((current_gradient*10)+0.5)));	// round to one digit
			}
		}
	}

	// todo: taking direction from Hough lines could be even more accurate

	// find the gradient that occurs most often, this direction is used to rotate the map
	int max_number = 0;
	double most_occurring_gradient = 0.0;
	std::set<double> done_gradients;
	for(std::vector<double>::iterator grad=gradient_directions.begin(); grad!=gradient_directions.end(); ++grad)
	{
		// if gradient has been done, don't check it again
		if(done_gradients.find(*grad)==done_gradients.end())
		{
			int current_count = std::count(gradient_directions.begin(), gradient_directions.end(), *grad);
//			std::cout << "current gradient: " << *grad << ", occurs " << current_count << " times." << std::endl;
			if(current_count > max_number)
			{
				max_number = current_count;
				most_occurring_gradient = *grad;
			}
			done_gradients.insert(*grad);
		}
	}
	std::cout << "most occurring gradient angle: " << most_occurring_gradient << std::endl;

	// rotation angle of the map s.t. the most occurring gradient is in 90 degree to the x-axis
	double rotation_angle = most_occurring_gradient-PI/2; //std::abs(most_occurring_gradient)-PI/2;
	std::cout << "rotation angle: " << rotation_angle << std::endl;

	// get rotation matrix R for rotating the image around the center of the room contour
	//	Remark: rotation angle in degrees for opencv
	std::vector < std::vector<cv::Point> > contour;
	cv::Mat contour_map = room_map.clone();
	cv::findContours(contour_map, contour, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);

	// get the moment--> for a given map, there should only be one contour
	cv::Moments moment = cv::moments(contour[0], false);

	// calculate rotation center
	cv::Point2f center = cv::Point(moment.m10/moment.m00 , moment.m01/moment.m00 );
	cv::Mat R = cv::getRotationMatrix2D(center, (rotation_angle*180)/PI, 1.0);

	// determine bounding rectangle to find the size of the new image
	cv::Rect bbox = cv::RotatedRect(center, room_map.size(), (rotation_angle*180)/PI).boundingRect();

	// adjust transformation matrix
	R.at<double>(0,2) += bbox.width/2.0 - center.x;
	R.at<double>(1,2) += bbox.height/2.0 - center.y;

	// rotate the image
	cv::Mat rotated_room_map;
	cv::warpAffine(room_map, rotated_room_map, R, bbox.size(), cv::INTER_NEAREST);

	// apply a binary filter to create a binary image, also use a closing operator to smooth the output (the rotation might produce
	// black pixels reaching into the white area that were not there before, causing new, wrong cells to open)
	cv::threshold(rotated_room_map, rotated_room_map, 200, 255, CV_THRESH_BINARY);
	cv::dilate(rotated_room_map, rotated_room_map, cv::Mat(), cv::Point(-1,-1), 1);
	cv::erode(rotated_room_map, rotated_room_map, cv::Mat(), cv::Point(-1,-1), 1);

	// testing
//	cv::Mat room_map_disp = room_map.clone();
//	cv::circle(room_map_disp, starting_position, 3, cv::Scalar(160), CV_FILLED);
//	cv::imshow("room_map", room_map_disp);
//	std::vector<cv::Point> tester;
//	tester.push_back(cv::Point(10,10));
//	cv::Mat tester_map = room_map.clone();
//	cv::circle(tester_map, tester[0], 3, cv::Scalar(127), CV_FILLED);
//	cv::transform(tester, tester, R);
//	cv::circle(rotated_room_map, tester[0], 3, cv::Scalar(127), CV_FILLED);
//	cv::imshow("original", tester_map);
//	cv::imshow("rotated_im.png", rotated_room_map);
//	cv::waitKey();

	ROS_INFO("Planning the boustrophedon path trough the room.");
	// *********************** II. Sweep a slice trough the map and mark the found cell boundaries. ***********************
	// create a map copy to mark the cell boundaries
	cv::Mat cell_map = rotated_room_map.clone();

	// find smallest y-value for that a white pixel occurs, to set initial y value and find initial number of segments
	size_t y_start = 0;
	int n_start = 0;
	bool found = false, obstacle = false;
	for(size_t y=0; y<rotated_room_map.rows; ++y)
	{
		for(size_t x=0; x<rotated_room_map.cols; ++x)
		{
			if(rotated_room_map.at<uchar>(y,x) == 255 && found == false)
			{
				y_start = y;
				found = true;
			}
			else if(found == true && obstacle == false && rotated_room_map.at<uchar>(y,x) == 0)
			{
				++n_start;
				obstacle = true;
			}
			else if(found == true && obstacle == true && rotated_room_map.at<uchar>(y,x) == 255)
			{
				obstacle = false;
			}
		}

		if(found == true)
			break;
	}

	// swipe trough the map and detect critical points
	int previous_number_of_segments = n_start;
	for(size_t y=y_start+1; y<rotated_room_map.rows; ++y) // start at y_start+1 because we know number of segments at y_start
	{
		int number_of_segments = 0; // int to count how many segments at the current slice are
		bool obstacle_hit = false; // bool to check if the line currently hit an obstacle, s.t. not all black pixels trigger an event
		bool hit_white_pixel = false; // bool to check if a white pixel has been hit at the current slice, to start the slice at the first white pixel

		for(size_t x=0; x<rotated_room_map.cols; ++x)
		{
			if(rotated_room_map.at<uchar>(y,x) == 255 && hit_white_pixel == false)
				hit_white_pixel = true;
			else if(hit_white_pixel == true)
			{
				if(obstacle_hit == false && rotated_room_map.at<uchar>(y,x) == 0) // check for obstacle
				{
					++number_of_segments;
					obstacle_hit = true;
				}
				else if(obstacle_hit == true && rotated_room_map.at<uchar>(y,x) == 255) // check for leaving obstacle
				{
					obstacle_hit = false;
				}
			}
		}

		// reset hit_white_pixel to use this Boolean later
		hit_white_pixel = false;

		// check if number of segments has changed --> event occurred
		if(previous_number_of_segments < number_of_segments) // IN event
		{
			// check the current slice again for critical points
			for(int x=0; x<rotated_room_map.cols; ++x)
			{
				if(rotated_room_map.at<uchar>(y,x) == 255 && hit_white_pixel == false)
					hit_white_pixel = true;

				else if(hit_white_pixel == true && rotated_room_map.at<uchar>(y,x) == 0)
				{
					// check over black pixel for other black pixels, if none occur a critical point is found
					bool critical_point = true;
					for(int dx=-1; dx<=1; ++dx)
						if(rotated_room_map.at<uchar>(y-1,x+dx) == 0)
							critical_point = false;

					// if a critical point is found mark the separation, note that this algorithm goes left and right
					// starting at the critical point until an obstacle is hit, because this prevents unnecessary cells
					// behind other obstacles on the same y-value as the critical point
					if(critical_point == true)
					{
						// to the left until a black pixel is hit
						for(int dx=-1; x+dx>0; --dx)
						{
							if(cell_map.at<uchar>(y,x+dx) == 255)
								cell_map.at<uchar>(y,x+dx) = 0;
							else if(cell_map.at<uchar>(y,x+dx) == 0)
								break;
						}

						// to the right until a black pixel is hit
						for(int dx=1; x+dx<rotated_room_map.cols; ++dx)
						{
							if(cell_map.at<uchar>(y,x+dx) == 255)
								cell_map.at<uchar>(y,x+dx) = 0;
							else if(cell_map.at<uchar>(y,x+dx) == 0)
								break;
						}
					}
				}
			}
		}
		else if(previous_number_of_segments > number_of_segments) // OUT event
		{
			// check the previous slice again for critical points --> y-1
			for(int x=0; x<rotated_room_map.cols; ++x)
			{
				if(rotated_room_map.at<uchar>(y-1,x) == 255 && hit_white_pixel == false)
					hit_white_pixel = true;

				else if(hit_white_pixel == true && rotated_room_map.at<uchar>(y-1,x) == 0)
				{
					// check over black pixel for other black pixels, if none occur a critical point is found
					bool critical_point = true;
					for(int dx=-1; dx<=1; ++dx)
						if(rotated_room_map.at<uchar>(y,x+dx) == 0) // check at side after obstacle
							critical_point = false;

					// if a critical point is found mark the separation, note that this algorithm goes left and right
					// starting at the critical point until an obstacle is hit, because this prevents unnecessary cells
					// behind other obstacles on the same y-value as the critical point
					if(critical_point == true)
					{
						// to the left until a black pixel is hit
						for(int dx=-1; x+dx>0; --dx)
						{
							if(cell_map.at<uchar>(y-1,x+dx) == 255)
								cell_map.at<uchar>(y-1,x+dx) = 0;
							else if(cell_map.at<uchar>(y-1,x+dx) == 0)
								break;
						}

						// to the right until a black pixel is hit
						for(int dx=1; x+dx<rotated_room_map.cols; ++dx)
						{
							if(cell_map.at<uchar>(y-1,x+dx) == 255)
								cell_map.at<uchar>(y-1,x+dx) = 0;
							else if(cell_map.at<uchar>(y-1,x+dx) == 0)
								break;
						}
					}
				}
			}
		}

		// save the found number of segments
		previous_number_of_segments = number_of_segments;
	}

#ifdef DEBUG_VISUALIZATION
	cv::imshow("cell_map", cell_map);
#endif

	// *********************** III. Find the separated cells. ***********************
	std::vector<std::vector<cv::Point> > cells;
	cv::Mat cell_copy = cell_map.clone();
	cv::findContours(cell_copy, cells, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
//	 testing
//	cv::Mat black_map = cv::Mat(cell_map.rows, cell_map.cols, cell_map.type(), cv::Scalar(0));
//	for(size_t i=0; i<cells.size(); ++i)
//	{
//		for(size_t j=0; j<cells[i].size(); ++j)
//		{
//			cv::circle(black_map, cells[i][j], 2, cv::Scalar(127), CV_FILLED);
//			cv::imshow("contours", black_map);
//			cv::waitKey();
//		}
//	}

	// create generalized Polygons out of the contours to handle the cells
	std::vector<GeneralizedPolygon> cell_polygons;
	std::vector<cv::Point> polygon_centers;
	for(size_t cell=0; cell<cells.size(); ++cell)
	{
		if(cv::contourArea(cells[cell])>=min_cell_area)
		{
			GeneralizedPolygon current_cell(cells[cell]);
			cell_polygons.push_back(current_cell);
			polygon_centers.push_back(current_cell.getCenter());
		}
	}

	ROS_INFO("Found the cells in the given map.");

	// *********************** IV. Determine the cell paths. ***********************
	// determine the start cell that contains the start position
	int start_cell_index = 0;
	cv::Point starting_point(starting_position.x, starting_position.y); // conversion of Pose2D to cv::Point for convenience

//	testing
//	cv::Mat center_map = room_map.clone();
//	for(size_t i=0; i<cell_polygons.size(); ++i)
//		cv::circle(center_map, cell_polygons[i].getCenter(), 2, cv::Scalar(127), CV_FILLED);
//	cv::circle(center_map, starting_point, 4, cv::Scalar(100), CV_FILLED);
//	cv::imshow("centers", center_map);
//	cv::waitKey();

	for(std::vector<GeneralizedPolygon>::iterator cell=cell_polygons.begin(); cell!=cell_polygons.end(); ++cell)
		if(cv::pointPolygonTest(cell->getVertexes(), starting_point, false) >= 0)
			start_cell_index = cell - cell_polygons.begin();

	// determine the optimal visiting order of the cells
	ConcordeTSPSolver tsp_solver;
	std::vector<int> optimal_order = tsp_solver.solveConcordeTSP(rotated_room_map, polygon_centers, 0.25, 0.0, map_resolution, start_cell_index, 0);

	// go trough the cells and determine the boustrophedon paths
	ROS_INFO("Starting to get the paths for each cell, number of cells: %d", (int)cell_polygons.size());
	int coverage_radius_as_int = (int)std::floor(coverage_radius); // convert fov-radius to int
	std::vector<cv::Point> starting_point_vector(1, starting_point); // opencv syntax
	cv::transform(starting_point_vector, starting_point_vector, R);
	cv::Point robot_pos = starting_point_vector[0]; // Point that keeps track of the last point after the boustrophedon path in each cell
	//cv::Point robot_pos = starting_point;
	std::vector<cv::Point> fov_middlepoint_path;
	for(size_t cell=0; cell<cell_polygons.size(); ++cell)
	{
		// access current cell
		GeneralizedPolygon& current_cell = cell_polygons[optimal_order[cell]];

		// get a map that has only the current cell drawn in
		//	Remark:	single cells are obstacle free so it is sufficient to use the cell to check if a position can be reached during the
		//			execution of the coverage path
		cv::Mat current_cell_map;
		current_cell.drawPolygon(current_cell_map, cv::Scalar(255));

		// get the longest edge of the current cell and rotate it s.t. this edge is parallel to the x-axis, because this allows to
		// find a path along this edge, which minimizes the turns of the robot during the execution of the cell path
		//cv::Point2d edge = current_cell.getLongestEdge(); // todo: proceed here
		double edge_angle = current_cell.getLongestEdgeAngle(); //std::atan2(edge.y, edge.x);
		cv::Point cell_center = current_cell.getCenter();
		cv::Mat R_cell = cv::getRotationMatrix2D(cell_center, -(edge_angle*180)/PI, 1.0);

		// determine bounding rectangle to find the size of the new image
		cv::Rect cell_bbox = cv::RotatedRect(cell_center, rotated_room_map.size(), -(edge_angle*180)/PI).boundingRect();

		// adjust transformation matrix
		R_cell.at<double>(0,2) += cell_bbox.width/2.0 - cell_center.x;
		R_cell.at<double>(1,2) += cell_bbox.height/2.0 - cell_center.y;

		// rotate the image
		cv::Mat rotated_cell_map;
		cv::warpAffine(current_cell_map, rotated_cell_map, R_cell, cell_bbox.size(), cv::INTER_NEAREST);

		// apply a binary filter to create a binary image, also use a closing operator to smooth the output (the rotation might produce
		// black pixels reaching into the white area that were not there before, causing new, wrong cells to open)
		cv::threshold(rotated_cell_map, rotated_cell_map, 200, 255, CV_THRESH_BINARY);
		cv::dilate(rotated_cell_map, rotated_cell_map, cv::Mat(), cv::Point(-1,-1), 1);
		cv::erode(rotated_cell_map, rotated_cell_map, cv::Mat(), cv::Point(-1,-1), 1);

		// get the min/max x/y values for this cell
		int min_x=100000, max_x=0, min_y=100000, max_y=0;
		std::vector<cv::Point> rotated_vertexes = current_cell.getVertexes();
		cv::transform(rotated_vertexes, rotated_vertexes, R_cell);
		for(size_t point=0; point<rotated_vertexes.size(); ++point)
		{
			if(rotated_vertexes[point].x > max_x)
				max_x = rotated_vertexes[point].x;
			if(rotated_vertexes[point].y > max_y)
				max_y = rotated_vertexes[point].y;
			if(rotated_vertexes[point].x < min_x)
				min_x = rotated_vertexes[point].x;
			if(rotated_vertexes[point].y < min_y)
				min_y = rotated_vertexes[point].y;
		}

		// invert the rotation matrix to remap the determined points to the original cell
		cv::Mat R_cell_inv;
		cv::invertAffineTransform(R_cell, R_cell_inv);

		// get the left and right edges of the path
		std::vector<BoustrophedonHorizontalLine> path_lines;
		int y, dx;

		// check where to start the planning of the path (if the cell is smaller that the fov_diameter start in the middle of it)
		if((max_y - min_y) <= 2.0*coverage_radius_as_int)
			y = min_y + 0.5 * (max_y - min_y);
		else
			y = (min_y-1) + coverage_radius_as_int;
		do
		{
			BoustrophedonHorizontalLine current_line;
			cv::Point left_edge(-1, -1), right_edge(-1, -1);
			// check the for the current row to the right/left for the first white pixel (valid position), starting from
			// the minimal/maximal x value
			dx = min_x;
			bool found = false;
			// get the leftmost edges of the path
			do
			{
				if(rotated_cell_map.at<uchar>(y, dx) == 255 && rotated_cell_map.at<uchar>(y, dx+coverage_radius_as_int) == 255)
				{
					left_edge = cv::Point(dx+coverage_radius_as_int, y); // add coverage radius s.t. the edge is not on the wall
					found = true;
				}
				else
					++dx;
			}while(dx < (rotated_cell_map.cols-coverage_radius_as_int) && found == false); // dx < ... --> safety, should never hold

			// get the rightmost edges of the path
			dx = max_x;
			found = false;
			do
			{
				if(rotated_cell_map.at<uchar>(y, dx) == 255 && rotated_cell_map.at<uchar>(y, dx-coverage_radius_as_int) == 255)
				{
					right_edge = cv::Point(dx-coverage_radius_as_int, y); // subtract coverage radius s.t. edge is not on the wall
					found = true;
				}
				else
					--dx;
			}while(dx >= coverage_radius_as_int && found == false);

			// save found horizontal line, if one is found, transformed to the original orientation of the cell
			if(left_edge.x>=0 && left_edge.y>=0 && right_edge.x>=0 && right_edge.y>=0)
			{
				current_line.left_edge_ = left_edge;
				current_line.right_edge_ = right_edge;
				path_lines.push_back(current_line);
			}

			// increase y by given coverage-radius value
			y += 2*coverage_radius_as_int;

		}while(y <= max_y);

#ifdef DEBUG_VISUALIZATION
		// display
		cv::Mat rotated_cell_map_disp = rotated_cell_map.clone();
		for (size_t i=0; i<path_lines.size(); ++i)
			cv::line(rotated_cell_map_disp, path_lines[i].left_edge_, path_lines[i].right_edge_, cv::Scalar(128), 1);
		cv::imshow("rotated_cell_map", rotated_cell_map_disp);
#endif

		// if no edge could be found in the cell (e.g. if it is too small), ignore it
		if(path_lines.size()==0)
			continue;

		// get the edge nearest to the current robot position to start the boustrophedon path at by looking at the
		// upper and lower horizontal path (possible nearest locations) for the edges transformed to the original coordinates (easier)
		std::vector<cv::Point> outer_edges(4);
		outer_edges[0] = path_lines[0].left_edge_;
		outer_edges[1] = path_lines[0].right_edge_;
		outer_edges[2] = path_lines.back().left_edge_;
		outer_edges[3] = path_lines.back().right_edge_;
		cv::transform(outer_edges, outer_edges, R_cell_inv);
		double dist1 = path_planner_.planPath(rotated_room_map, robot_pos, outer_edges[0], 1.0, 0.0, map_resolution);
		double dist2 = path_planner_.planPath(rotated_room_map, robot_pos, outer_edges[1], 1.0, 0.0, map_resolution);
		double dist3= path_planner_.planPath(rotated_room_map, robot_pos, outer_edges[2], 1.0, 0.0, map_resolution);
		double dist4 = path_planner_.planPath(rotated_room_map, robot_pos, outer_edges[3], 1.0, 0.0, map_resolution);

		bool start_from_upper_path = true;
		bool start_from_left = true; // Boolean to determine on which side the path should start and to check where the path ended
		if((dist3 < dist1 && dist3 < dist2) || (dist4 < dist1 && dist4 < dist2)) // start on lower line
		{
			start_from_upper_path = false;
			if(dist4 < dist3)
				start_from_left = false;
		}
		else
			if(dist2 < dist1)
				start_from_left = false;

		cv::Mat rotated_room_map_disp = rotated_room_map.clone();
		for (size_t i=0; i<outer_edges.size(); i+=2)
			cv::line(rotated_room_map_disp, outer_edges[i], outer_edges[i+1], cv::Scalar(128), 1);
		cv::circle(rotated_room_map_disp, robot_pos, 3, cv::Scalar(160), CV_FILLED);
		if (start_from_upper_path == true)
		{
			if (start_from_left == true)
				cv::circle(rotated_room_map_disp, outer_edges[0], 3, cv::Scalar(64), CV_FILLED);
			else
				cv::circle(rotated_room_map_disp, outer_edges[1], 3, cv::Scalar(64), CV_FILLED);
		}
		else
		{
			if (start_from_left == true)
				cv::circle(rotated_room_map_disp, outer_edges[2], 3, cv::Scalar(64), CV_FILLED);
			else
				cv::circle(rotated_room_map_disp, outer_edges[3], 3, cv::Scalar(64), CV_FILLED);
		}
#ifdef DEBUG_VISUALIZATION
		cv::imshow("rotated_room_map", rotated_room_map_disp);
#endif

//		// todo: necessary?
//		// map the robot position and the room map after the last cell path to the new rotated coordinates
//		std::vector<cv::Point> current_pos_vector(1); // opencv syntax
//		current_pos_vector[0] = robot_pos;
//		cv::transform(current_pos_vector, current_pos_vector, R_cell);
//		cv::Point cell_robot_pos = current_pos_vector[0];
//		// set the robot position to the one in rotated coordinates
//		robot_pos = cell_robot_pos;
		cv::Point cell_robot_pos;

		// calculate the points between the edge points and create the boustrophedon path with this
		bool start = true;
		std::vector<cv::Point> current_fov_path;
		if(start_from_upper_path == true) // plan the path starting from upper horizontal line
		{
			for(std::vector<BoustrophedonHorizontalLine>::iterator line=path_lines.begin(); line!=path_lines.end(); ++line)
			{
				if(start == true) // at the beginning of path planning start at first horizontal line --> no vertical points between lines
				{
					if(start_from_left == true)
						cell_robot_pos = line->left_edge_;
					else
						cell_robot_pos = line->right_edge_;
					start = false;
				}

				if(start_from_left == true) // plan path to left and then to right edge
				{
					// get points between horizontal lines by using the Astar-path
					std::vector<cv::Point> astar_path;
					path_planner_.planPath(rotated_cell_map, cell_robot_pos, line->left_edge_, 1.0, 0.0, map_resolution, 0, &astar_path);
					for(size_t path_point=0; path_point<astar_path.size(); ++path_point)
					{
						if(cv::norm(cell_robot_pos - astar_path[path_point]) >= path_eps)
						{
							current_fov_path.push_back(astar_path[path_point]);
							cell_robot_pos = astar_path[path_point];
						}
					}
					current_fov_path.push_back(line->left_edge_);

					// get points between left and right edge
					int dx = path_eps;
					while((line->left_edge_.x+dx) < line->right_edge_.x)
					{
						current_fov_path.push_back(cv::Point(line->left_edge_.x+dx, line->left_edge_.y));
						dx += path_eps;
					}
					current_fov_path.push_back(line->right_edge_);

					// set robot position to right
					cell_robot_pos = line->right_edge_;
					start_from_left = false;
				}
				else // plan path to right then to left edge
				{
					// get points between horizontal lines
					std::vector<cv::Point> astar_path;
					path_planner_.planPath(rotated_cell_map, cell_robot_pos, line->right_edge_, 1.0, 0.0, map_resolution, 0, &astar_path);
					for(size_t path_point=0; path_point<astar_path.size(); ++path_point)
					{
						if(cv::norm(cell_robot_pos - astar_path[path_point]) >= path_eps)
						{
							current_fov_path.push_back(astar_path[path_point]);
							cell_robot_pos = astar_path[path_point];
						}
					}
					current_fov_path.push_back(line->right_edge_);

					// get points between left and right edge
					int dx = -path_eps;
					while((line->right_edge_.x+dx) > line->left_edge_.x)
					{
						current_fov_path.push_back(cv::Point(line->right_edge_.x+dx, line->right_edge_.y));
						dx -= path_eps;
					}
					current_fov_path.push_back(line->left_edge_);

					// set robot position to right
					cell_robot_pos = line->left_edge_;
					start_from_left = true;
				}
			}
		}
		else // plan the path from the lower horizontal line
		{
			for(std::vector<BoustrophedonHorizontalLine>::reverse_iterator line=path_lines.rbegin(); line!=path_lines.rend(); ++line)
			{
				if(start == true) // at the beginning of path planning start at first horizontal line --> no vertical points between lines
				{
					if(start_from_left == true)
						cell_robot_pos = line->left_edge_;
					else
						cell_robot_pos = line->right_edge_;
					start = false;
				}

				if(start_from_left == true) // plan path to left and then to right edge
				{
					// get points between horizontal lines
					std::vector<cv::Point> astar_path;
					path_planner_.planPath(rotated_cell_map, cell_robot_pos, line->left_edge_, 1.0, 0.0, map_resolution, 0, &astar_path);
					for(size_t path_point=0; path_point<astar_path.size(); ++path_point)
					{
						if(cv::norm(cell_robot_pos - astar_path[path_point]) >= path_eps)
						{
							current_fov_path.push_back(astar_path[path_point]);
							cell_robot_pos = astar_path[path_point];
						}
					}
					current_fov_path.push_back(line->left_edge_);

					// get points between left and right edge
					int dx = path_eps;
					while((line->left_edge_.x+dx) < line->right_edge_.x)
					{
						current_fov_path.push_back(cv::Point(line->left_edge_.x+dx, line->left_edge_.y));
						dx += path_eps;
					}
					current_fov_path.push_back(line->right_edge_);

					// set robot position to right
					cell_robot_pos = line->right_edge_;
					start_from_left = false;
				}
				else // plan path to right then to left edge
				{
					// get points between horizontal lines
					std::vector<cv::Point> astar_path;
					path_planner_.planPath(rotated_cell_map, cell_robot_pos, line->right_edge_, 1.0, 0.0, map_resolution, 0, &astar_path);
					for(size_t path_point=0; path_point<astar_path.size(); ++path_point)
					{
						if(cv::norm(cell_robot_pos - astar_path[path_point]) >= path_eps)
						{
							current_fov_path.push_back(astar_path[path_point]);
							cell_robot_pos = astar_path[path_point];
						}
					}
					current_fov_path.push_back(line->right_edge_);

					// get points between left and right edge
					int dx = -path_eps;
					while((line->right_edge_.x+dx) > line->left_edge_.x)
					{
						current_fov_path.push_back(cv::Point(line->right_edge_.x+dx, line->right_edge_.y));
						dx -= path_eps;
					}
					current_fov_path.push_back(line->left_edge_);

					// set robot position to right
					cell_robot_pos = line->left_edge_;
					start_from_left = true;
				}
			}
		}

		// remap the fov path to the originally rotated cell and add the found points to the global path
		cv::transform(current_fov_path, current_fov_path, R_cell_inv);
		for(std::vector<cv::Point>::iterator point=current_fov_path.begin(); point!=current_fov_path.end(); ++point)
			fov_middlepoint_path.push_back(*point);

		// also update the current robot position
		std::vector<cv::Point> current_pos_vector(1, cell_robot_pos);
		cv::transform(current_pos_vector, current_pos_vector, R_cell_inv);
		robot_pos = current_pos_vector[0];
	}

	// transform the calculated path back to the originally rotated map
	cv::Mat R_inv;
	cv::invertAffineTransform(R, R_inv);
	cv::transform(fov_middlepoint_path, fov_middlepoint_path, R_inv);

#ifdef DEBUG_VISUALIZATION
	// testing
	std::cout << "printing path" << std::endl;
	cv::Mat room_map_path = room_map.clone();
	cv::circle(room_map_path, starting_position, 3, cv::Scalar(160), CV_FILLED);
	for(size_t i=0; i<fov_middlepoint_path.size()-1; ++i)
	{
		cv::circle(room_map_path, fov_middlepoint_path[i], 2, cv::Scalar(200), CV_FILLED);
		cv::line(room_map_path, fov_middlepoint_path[i], fov_middlepoint_path[i+1], cv::Scalar(100), 1);
	}
	cv::circle(room_map_path, fov_middlepoint_path.back(), 2, cv::Scalar(200), CV_FILLED);
//	for(size_t i=0; i<optimal_order.size()-1; ++i)
//		cv::line(room_map_path, polygon_centers[optimal_order[i]], polygon_centers[optimal_order[i+1]], cv::Scalar(100), 1);
	cv::imshow("room_map_path", room_map_path);
	cv::waitKey();
#endif

	// create poses with an angle
	std::vector<geometry_msgs::Pose2D> fov_poses;
	for(size_t point_index=0; point_index<fov_middlepoint_path.size(); ++point_index)
	{
		// get the vector from the current point to the next point
		cv::Point current_point = fov_middlepoint_path[point_index];
		cv::Point next_point = fov_middlepoint_path[(point_index+1)%(fov_middlepoint_path.size())];
		cv::Point vector = next_point - current_point;

		float angle = std::atan2(vector.y, vector.x);

		// add the next navigation goal to the path
		geometry_msgs::Pose2D current_pose;
		current_pose.x = current_point.x;
		current_pose.y = current_point.y;
		if (point_index < fov_middlepoint_path.size()-1)
			current_pose.theta = angle;
		else
			current_pose.theta = fov_poses.back().theta;

		fov_poses.push_back(current_pose);
	}

	ROS_INFO("Found the cell paths.");

	// if the path should be planned for the robot footprint create the path and return here
	if(plan_for_footprint == true)
	{
		for(std::vector<geometry_msgs::Pose2D>::iterator pose=fov_poses.begin(); pose != fov_poses.end(); ++pose)
		{
			geometry_msgs::Pose2D current_pose;
			current_pose.x = (pose->x * map_resolution) + map_origin.x;
			current_pose.y = (pose->y * map_resolution) + map_origin.y;
			current_pose.theta = pose->theta;
			path.push_back(current_pose);
		}
		return;
	}

	// *********************** V. Get the robot path out of the fov path. ***********************
	// go trough all computed fov poses and compute the corresponding robot pose
	ROS_INFO("Starting to map from field of view pose to robot pose");
	mapPath(room_map, path, fov_poses, robot_to_fov_vector, map_resolution, map_origin, starting_position);

//	testing
//	std::cout << "printing path" << std::endl;
//	cv::Mat fov_path_map = room_map.clone();
//	for(size_t i=0; i<fov_middlepoint_path.size()-1; ++i)
//	{
//		cv::circle(fov_path_map, cv::Point(path[i].x/map_resolution, path[i].y/map_resolution), 2, cv::Scalar(200), CV_FILLED);
//		cv::line(fov_path_map, cv::Point(path[i].x/map_resolution, path[i].y/map_resolution), cv::Point(path[i+1].x/map_resolution, path[i+1].y/map_resolution), cv::Scalar(100), 1);
//		cv::imshow("cell path", fov_path_map);
//		cv::waitKey();
//	}
//	cv::circle(fov_path_map, cv::Point(path.back().x/map_resolution, path.back().y/map_resolution), 2, cv::Scalar(200), CV_FILLED);
//	cv::imshow("cell path", fov_path_map);
//	cv::waitKey();
}
